{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from apyori import apriori  \n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pddtrain=[]\n",
    "pddtest=[]\n",
    "a=[]\n",
    "ytrain=[]\n",
    "ytest=[]\n",
    "fuzzy_rules=[]\n",
    "bell_func_parameters=[]\n",
    "w1=[]\n",
    "w2=[]\n",
    "err1=[]\n",
    "bias1=[]\n",
    "bias2=1\n",
    "o1=[]\n",
    "i1=[]\n",
    "x=[]\n",
    "y=[]\n",
    "info_of_each_no=[]\n",
    "association_rules=[]\n",
    "actualx=[]\n",
    "actualx1=[]\n",
    "actualy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1=pd.read_csv(\"1-s2.0-S001048251730001X-mmc4.csv\")\n",
    "#table2=pd.read_csv(\"1-s2.0-S001048251730001X-mmc4.csv\")\n",
    "# table1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1.sample(frac=1)\n",
    "table1 = table1.sample(frac=1).reset_index(drop=True)\n",
    "# table1=table1.values\n",
    "table1=np.asarray(table1)\n",
    "actualx=table1[:,:-1]\n",
    "actualy=table1[:,-1:]\n",
    "# table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(22):\n",
    "    info_of_each_no.append([])\n",
    "data=[]\n",
    "for i in range(table1.shape[0]):\n",
    "    data.append([])\n",
    "    for j in range(table1.shape[1]):\n",
    "        if j==0:\n",
    "            if table1[i][j]==1:\n",
    "                data[i].append(2)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[2].append(table1[i][j])\n",
    "            else:\n",
    "                data[i].append(3)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[3].append(table1[i][j])\n",
    "        elif j==1:\n",
    "            if table1[i][j]<=21:\n",
    "                data[i].append(4)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[4].append(table1[i][j])\n",
    "            elif table1[i][j]<=34:\n",
    "                data[i].append(5)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[5].append(table1[i][j])\n",
    "            else:\n",
    "                data[i].append(6)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[6].append(table1[i][j])\n",
    "        elif j==2:\n",
    "            if table1[i][j]<=2:\n",
    "                data[i].append(7)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[7].append(table1[i][j])\n",
    "            elif table1[i][j]<=4:\n",
    "                data[i].append(8)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[8].append(table1[i][j])\n",
    "            elif table1[i][j]<=7:\n",
    "                data[i].append(9)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[9].append(table1[i][j])\n",
    "            else:\n",
    "                data[i].append(10)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[10].append(table1[i][j])\n",
    "        elif j==3:\n",
    "            if table1[i][j]<=6:\n",
    "                data[i].append(11)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[11].append(table1[i][j])\n",
    "            else:\n",
    "                data[i].append(12)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[12].append(table1[i][j])\n",
    "        elif j==4:\n",
    "            if table1[i][j]==1:\n",
    "                data[i].append(13)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[13].append(table1[i][j])\n",
    "            elif table1[i][j]==2:\n",
    "                data[i].append(14)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[14].append(table1[i][j])\n",
    "            else:\n",
    "                data[i].append(15)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[15].append(table1[i][j])\n",
    "        elif j==5:\n",
    "            if table1[i][j]<=110:\n",
    "                data[i].append(16)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[16].append(table1[i][j])\n",
    "            elif table1[i][j]<=390:\n",
    "                data[i].append(17)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[17].append(table1[i][j])\n",
    "            else:\n",
    "                data[i].append(18)\n",
    "                if table1[i][-1]==1:\n",
    "                    info_of_each_no[18].append(table1[i][j])\n",
    "        elif j==6:\n",
    "            if table1[i][j]<=15:\n",
    "                data[i].append(19)\n",
    "                info_of_each_no[19].append(table1[i][j])\n",
    "            elif table1[i][j]<=49:\n",
    "                data[i].append(20)\n",
    "                info_of_each_no[20].append(table1[i][j])\n",
    "            else:\n",
    "                data[i].append(21)\n",
    "                info_of_each_no[21].append(table1[i][j])\n",
    "        elif j==7:\n",
    "            data[i].append(int(table1[i][j]))\n",
    "            info_of_each_no[int(table1[i][j])].append(table1[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    x.append(data[i][:-1])\n",
    "    y.append(data[i][-1])   \n",
    "x=np.asarray(x)\n",
    "y=np.asarray(y)\n",
    "actualx=np.asarray(actualx)\n",
    "actualy=np.asarray(actualy)\n",
    "actualx1=actualx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbellmf(x, a, b, c):\n",
    "    return 1. / (1. + np.abs((x - c) / a) ** (2 * b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infoD(y):\n",
    "    c1=np.sum(y)\n",
    "    c2=(y.shape[0]-c1)/y.shape[0]\n",
    "    c1=c1/y.shape[0]\n",
    "    return -1*((c1*math.log(c1+1))+(c2*math.log(c2+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(x, y,value_of_attr):\n",
    "    infod=infoD(y)\n",
    "    gain=[]\n",
    "    for i in range(x.shape[1]):\n",
    "        temp=[[0,0] for i in range(len(value_of_attr[i]))]\n",
    "        for j in range(x.shape[0]):\n",
    "            for k in range(len(value_of_attr[i])):\n",
    "                if x[j][i]==value_of_attr[i][k]:\n",
    "                    if y[j]==1:\n",
    "                        temp[k][0]+=1\n",
    "                    else:\n",
    "                        temp[k][1]+=1\n",
    "        result=0\n",
    "        for j in range(len(value_of_attr[i])):\n",
    "            t=temp[j][0]+temp[j][1]\n",
    "            result+=(t/x.shape[0])*(-1*(((temp[j][0]/t)*math.log(temp[j][0]/t+1))+((temp[j][1]/t)*math.log(temp[j][1]/t+1))))\n",
    "        gain.append(infod-result)      \n",
    "    return gain    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection():\n",
    "    global pddtrain,pddtest,ytrain,ytest,a,fuzzy_rules,bell_func_parameters,bias1,bias2,w1,w2,i1,o1,err1,actualx,actualy\n",
    "    xtemp=pddtrain\n",
    "    ytemp=ytrain\n",
    "    infogain=information_gain(xtemp,ytemp,[[2,3],[4,5,6],[7,8,9,10],[11,12],[13,14,15],[16,17,18],[19,20,21]])\n",
    "    infogain_list=[]\n",
    "    for i in range(len(infogain)):\n",
    "        indx=infogain.index(max(infogain))\n",
    "        infogain[indx]=0\n",
    "        infogain_list.append(indx)\n",
    "    k=5 \n",
    "    pddtrain=np.delete(pddtrain,infogain_list[k:], axis=1)\n",
    "    actualx=np.delete(actualx,infogain_list[k:], axis=1)\n",
    "    a=[[2,3],[4,5,6],[7,8,9,10],[11,12],[13,14,15],[16,17,18],[19,20,21]]\n",
    "    a=np.asarray(a)\n",
    "    a=np.delete(a,infogain_list[k:], axis=0)\n",
    "    a=list(a)\n",
    "    ytrain=ytrain.reshape((ytrain.shape[0],1))\n",
    "    ytest=ytest.reshape((ytest.shape[0],1))\n",
    "    data1=np.append(pddtrain,ytrain, axis=1)\n",
    "    association_rules = apriori(data1, min_support=0.0289, min_confidence=0.6,min_lift=3, min_length=2)\n",
    "    association_results = list(association_rules)  \n",
    "    fuzzy_rules=[]\n",
    "    for i in range(len(association_results)):\n",
    "        if (0 in list(association_results[i][0])) or (1 in list(association_results[i][0])):\n",
    "            fuzzy_rules.append(list(association_results[i][0]))\n",
    "    bell_func_parameters=[]\n",
    "    for i in range(len(info_of_each_no)):\n",
    "        if len(info_of_each_no[i])!=0:\n",
    "            mean=np.mean(info_of_each_no[i])\n",
    "            bell_func_parameters.append([np.max(info_of_each_no[i])-mean+0.4,4,mean])\n",
    "        else:\n",
    "            bell_func_parameters.append([.1,4,-3])\n",
    "    w1=[[(1.0/(5.0))]*(pddtrain.shape[1]) for i in range(len(fuzzy_rules))]\n",
    "    w2=[(1.0/7)]*(len(fuzzy_rules))\n",
    "    i1=[0]*len(fuzzy_rules)\n",
    "    o1=[0]*len(fuzzy_rules)\n",
    "    err1=[0]*len(fuzzy_rules)\n",
    "    bias1=[1]*len(fuzzy_rules)\n",
    "    bias2=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wxx(wx):\n",
    "\tww=1/(1+pow( 2.71828,-wx))\n",
    "\treturn ww\n",
    "\n",
    "def wxxx(wx):\n",
    "\tww=1/(pow( 2.71828,-wx))\n",
    "\tif ww>0.5:\n",
    "\t\treturn 1\n",
    "\treturn 0\t\n",
    "\n",
    "def updateabc(x,a,b,c):\n",
    "    da=(2*b*pow(a,(2*b-1))*pow((x-c),(2*b)))/pow((pow(a,(2*b))+pow((x-c),(2*b))),2)\n",
    "    dc=(pow(a,(2*b))*2*b*pow((x-c),(2*b-1)))/pow((pow(a,(2*b))+pow((x-c),(2*b))),2)\n",
    "    try:\n",
    "        db=(-2*pow(a,(2*b))*pow((x-c),(2*b))*math.log((x-c)/a))/pow((pow(a,(2*b))+pow((x-c),(2*b))),2)\n",
    "    except:\n",
    "        db=(-2*pow(a,(2*b))*pow((x-c),(2*b)))/pow((pow(a,(2*b))+pow((x-c),(2*b))),2)\n",
    "    return [da,db,dc]\n",
    "\n",
    "def dbydwbar(w,x):\n",
    "    return (x*pow(2.71828,(w*x)))/pow((pow(2.71828,x)+1),2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneiteration():\n",
    "    global pddtrain,pddtest,ytrain,ytest,a,fuzzy_rules,bell_func_parameters,bias1,bias2,w1,w2,i1,o1,err1\n",
    "    serror=0\n",
    "    lrate=0.2\n",
    "    err1=[0]*len(fuzzy_rules)\n",
    "    for i in range(pddtrain.shape[0]):\n",
    "        ##############\n",
    "        vectr=[0]*22\n",
    "        for j in range(len(a)):\n",
    "            for kk in range(len(a[j])):\n",
    "                vectr[a[j][kk]]=gbellmf(pddtrain[i][j],*bell_func_parameters[a[j][kk]])     \n",
    "        layer2=[]\n",
    "        for ii in range(len(fuzzy_rules)):\n",
    "            val=0.0\n",
    "            for j in range(len(fuzzy_rules[ii])):\n",
    "                if fuzzy_rules[ii][j]!=0 and fuzzy_rules[ii][j]!=1:\n",
    "                    val=(val+vectr[fuzzy_rules[ii][j]])\n",
    "            layer2.append(val)    \n",
    "        sum_of_l2=sum(layer2)\n",
    "        layer3=[]\n",
    "        for ii in range(len(layer2)):\n",
    "            layer3.append(layer2[ii]/sum_of_l2)\n",
    "        ##############\n",
    "        error1=0\n",
    "        for ii in range(len(fuzzy_rules)):\n",
    "            i1[ii]=bias1[ii]\n",
    "            for j in range(pddtrain.shape[1]):\n",
    "                i1[ii]+=pddtrain[i][j]*w1[ii][j]\n",
    "            o1[ii]=wxx(i1[ii]*layer3[ii])\n",
    "        wx=bias2\n",
    "        for ii in range(len(fuzzy_rules)):\n",
    "            wx+=o1[ii]*w2[ii]\n",
    "        output=wxx(wx)\n",
    "        error1=ytrain[i]-wxxx(wx)\n",
    "        error=output*(1-output)*(ytrain[i]-output)\n",
    "        for ii in range(len(fuzzy_rules)):\n",
    "            err1[ii]=o1[ii]*(1-o1[ii])*(error*w2[ii])*layer3[ii]\n",
    "        for ii in range(len(fuzzy_rules)):\n",
    "            w2[ii]+=(lrate*o1[ii]*error)\n",
    "        for ii in range(len(fuzzy_rules)):\n",
    "            for j in range(pddtrain.shape[1]):\n",
    "                w1[ii][j]+=(lrate*2*layer3[ii]*pddtrain[i][j]*err1[ii])\n",
    "        ###################################################\n",
    "        vectr1=[0]*22\n",
    "        for rule in range(len(fuzzy_rules)):\n",
    "            val=error*dbydwbar(layer3[rule],i1[rule])*((sum(layer2)-layer2[rule])/pow(sum(layer2),2))\n",
    "            for j in range(len(fuzzy_rules[rule])):\n",
    "                if fuzzy_rules[rule][j]!=0 and fuzzy_rules[rule][j]!=1:\n",
    "                    vectr1[fuzzy_rules[rule][j]]+=val\n",
    "        learning_rate=.9          \n",
    "        for j in range(len(a)):\n",
    "            for kk in range(len(a[j])):\n",
    "                result=updateabc(pddtrain[i][j],*bell_func_parameters[a[j][kk]])\n",
    "                bell_func_parameters[a[j][kk]][0]+=result[0]*learning_rate*vectr1[a[j][kk]]\n",
    "                bell_func_parameters[a[j][kk]][0]+=result[1]*learning_rate*vectr1[a[j][kk]]\n",
    "                bell_func_parameters[a[j][kk]][0]+=result[2]*learning_rate*vectr1[a[j][kk]]\n",
    "        ###################################################\n",
    "        if error1!=0:\n",
    "            serror+=1\n",
    "    return serror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "    global pddtrain,pddtest,ytrain,ytest,a,fuzzy_rules,bell_func_parameters,bias1,bias2,w1,w2,i1,o1,err1\n",
    "    serror=0\n",
    "    for i in range(pddtest.shape[0]):\n",
    "        ################################\n",
    "        vectr=[0]*22\n",
    "        for j in range(len(a)):\n",
    "            for kk in range(len(a[j])):\n",
    "                vectr[a[j][kk]]=gbellmf(pddtest[i][j],*bell_func_parameters[a[j][kk]])     \n",
    "        layer2=[]\n",
    "        for ii in range(len(fuzzy_rules)):\n",
    "            val=0.0\n",
    "            for j in range(len(fuzzy_rules[ii])):\n",
    "                if fuzzy_rules[ii][j]!=0 and fuzzy_rules[ii][j]!=1:\n",
    "                    val=(val+vectr[fuzzy_rules[ii][j]])\n",
    "            layer2.append(val)    \n",
    "        sum_of_l2=sum(layer2)\n",
    "        layer3=[]\n",
    "        for ii in range(len(layer2)):\n",
    "            layer3.append(layer2[ii]/sum_of_l2)\n",
    "        ######################################\n",
    "        error1=0\n",
    "        i1=[0]*len(fuzzy_rules)\n",
    "        for ii in range(len(fuzzy_rules)):\n",
    "            i1[ii]=bias1[ii]\n",
    "            for j in range(pddtest.shape[1]):\n",
    "                i1[ii]+=pddtest[i][j]*w1[ii][j]\n",
    "            o1[ii]=wxx(i1[ii]*layer3[ii])\n",
    "        wx=bias2\n",
    "        for ii in range(len(fuzzy_rules)):\n",
    "            wx+=o1[ii]*w2[ii]\n",
    "        output=wxxx(wx)\n",
    "        error1=ytest[i]-output\n",
    "        #################################\n",
    "        if error1!=0:\n",
    "            serror+=1\n",
    "    return serror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is : 0.5555555555555556 best accuracy till now:  0.5555555555555556\n",
      "########################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anant/anaconda3/envs/shinnu/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in square\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is : 0.6 best accuracy till now:  0.6\n",
      "########################################################################\n",
      "accuracy is : 0.9 best accuracy till now:  0.9\n",
      "########################################################################\n",
      "accuracy is : 0.7 best accuracy till now:  0.9\n",
      "########################################################################\n",
      "accuracy is : 0.9 best accuracy till now:  0.9\n",
      "########################################################################\n",
      "accuracy is : 0.9 best accuracy till now:  0.9\n",
      "########################################################################\n",
      "accuracy is : 0.9 best accuracy till now:  0.9\n",
      "########################################################################\n",
      "accuracy is : 0.8 best accuracy till now:  0.9\n",
      "########################################################################\n",
      "average accuracy is = 0.7819444444444444 best accuracy:  0.9\n"
     ]
    }
   ],
   "source": [
    "def kfoldcv(iteration_val,nfolds):\n",
    "    global pddtrain,pddtest,ytrain,ytest,a,fuzzy_rules,bell_func_parameters,bias1,bias2,w1,w2,i1,o1,err1,actualx,actualx1,actualy,x,y\n",
    "    n=x.shape[0]\n",
    "    acc=0\n",
    "    l=0\n",
    "    avgacc=0.0\n",
    "    setsize=(n//nfolds)\n",
    "    err=0\n",
    "    k=(n//nfolds)\n",
    "    i=1\n",
    "    j=k\n",
    "    while j<n:\n",
    "        actualx=actualx1\n",
    "        pddtrain=np.append(x[:i],x[j:],axis=0)\n",
    "        ytrain=np.append(y[:i],y[j:],axis=0)\n",
    "        ytest=y[i:j]\n",
    "        pddtest=x[i:j]\n",
    "        feature_selection()\n",
    "        pddtrain=np.append(actualx[:i],actualx[j:],axis=0)\n",
    "        ytrain=np.append(actualy[:i],actualy[j:],axis=0)\n",
    "        ytest=actualy[i:j]\n",
    "        pddtest=actualx[i:j]\n",
    "        i=j\n",
    "        j=j+k\n",
    "        for ii in range(iteration_val):\n",
    "            err=oneiteration()\n",
    "            if err==0:\n",
    "                break;\n",
    "        racc=accuracy()\n",
    "        acc1=((pddtest.shape[0]-racc)*1.0)/pddtest.shape[0]\n",
    "        if acc<acc1:\n",
    "            acc=acc1\n",
    "        avgacc+=acc1\n",
    "        l+=1\n",
    "        print('accuracy is :',acc1,'best accuracy till now: ',acc)\n",
    "        print(\"########################################################################\")\t\t\t\t\n",
    "    return [(avgacc*1.0)/l, acc]\t\n",
    "\n",
    "acc=kfoldcv(100,9)\t\t\n",
    "print(\"average accuracy is =\",acc[0],\"best accuracy: \",acc[1])\t\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(12, input_dim=text_train.shape[1], activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(12, input_dim=text_train.shape[1], activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',)\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(text_train, y_train,\n",
    "#           epochs=10000,\n",
    "#           batch_size=128)\n",
    "# score = model.evaluate(text_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score\n",
    "# bell_func_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     result=oneiteration()\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shinnu",
   "language": "python",
   "name": "shinnu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
